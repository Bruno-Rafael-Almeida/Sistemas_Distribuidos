{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import webcolors\n",
    "\n",
    "# Define a função que retorna o nome da cor RGB mais próxima\n",
    "def get_color_name(rgb):\n",
    "    min_colors = {}\n",
    "    for key, name in webcolors.CSS3_HEX_TO_NAMES.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb[0]) ** 2\n",
    "        gd = (g_c - rgb[1]) ** 2\n",
    "        bd = (b_c - rgb[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "# Captura o vídeo da webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Lê um frame do vídeo\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Obtém as dimensões do frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Define o retângulo que delimita a região central do frame\n",
    "    x1 = int(0.25 * width)\n",
    "    y1 = int(0.25 * height)\n",
    "    x2 = int(0.75 * width)\n",
    "    y2 = int(0.75 * height)\n",
    "\n",
    "    # Segmenta a região central do frame\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Obtém a cor média da região central do frame\n",
    "    bgr_color = cv2.mean(roi)[:3]\n",
    "    rgb_color = tuple(reversed(bgr_color))\n",
    "    color_name = get_color_name(rgb_color)\n",
    "\n",
    "    # Escreve o nome da cor na imagem\n",
    "    cv2.putText(frame, color_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "    # Exibe a imagem resultante\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Espera pela tecla 'q' para sair do loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libera a captura de vídeo e fecha a janela\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import webcolors\n",
    "\n",
    "# Define a função que retorna o nome da cor RGB mais próxima\n",
    "def get_color_name(rgb):\n",
    "    min_colors = {}\n",
    "    for key, name in webcolors.CSS3_HEX_TO_NAMES.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb[0]) ** 2\n",
    "        gd = (g_c - rgb[1]) ** 2\n",
    "        bd = (b_c - rgb[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "# Captura o vídeo da webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Lê um frame do vídeo\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Obtém as dimensões do frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Define o retângulo que delimita a região central do frame\n",
    "    x1 = int(0.25 * width)\n",
    "    y1 = int(0.25 * height)\n",
    "    x2 = int(0.75 * width)\n",
    "    y2 = int(0.75 * height)\n",
    "\n",
    "    # Segmenta a região central do frame\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Obtém a cor média da região central do frame\n",
    "    bgr_color = cv2.mean(roi)[:3]\n",
    "    rgb_color = tuple(reversed(bgr_color))\n",
    "    color_name = get_color_name(rgb_color)\n",
    "\n",
    "    # Desenha um retângulo ao redor da região central do frame\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Escreve o nome da cor em português dentro do retângulo\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = f'Cor: {color_name}'\n",
    "    org = (x1 + 10, y1 + 30)\n",
    "    fontScale = 0.8\n",
    "    color = (255, 255, 255)\n",
    "    thickness = 2\n",
    "    cv2.putText(frame, text, org, font, fontScale, color, thickness)\n",
    "\n",
    "    # Exibe o vídeo resultante\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Espera pela tecla 'q' para sair do loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libera a captura de vídeo e fecha a janela\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carrega o modelo pré-treinado para detecção de pontos faciais\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Carrega o modelo pré-treinado para classificação de emoções\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Define um dicionário para mapear os rótulos de saída do modelo para emoções\n",
    "emotions = {\n",
    "    0: \"Raiva\",\n",
    "    1: \"Desgosto\",\n",
    "    2: \"Medo\",\n",
    "    3: \"Feliz\",\n",
    "    4: \"Triste\",\n",
    "    5: \"Surpresa\",\n",
    "    6: \"Neutro\"\n",
    "}\n",
    "\n",
    "# Inicializa a webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Captura o frame da webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Redimensiona o frame para melhor desempenho\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Converte o frame para escala de cinza\n",
    "    gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecta os pontos faciais no frame\n",
    "    faces = detector(gray)\n",
    "\n",
    "    # Itera sobre cada rosto detectado\n",
    "    for face in faces:\n",
    "        # Obtém os pontos faciais do rosto\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Converte os pontos faciais para um vetor NumPy\n",
    "        landmarks = np.array([(p.x, p.y) for p in landmarks.parts()])\n",
    "\n",
    "        # Redimensiona os pontos faciais para o tamanho original do frame\n",
    "        landmarks *= 4\n",
    "\n",
    "        # Extrai a região de interesse correspondente ao rosto\n",
    "        x1, y1 = np.min(landmarks, axis=0)\n",
    "        x2, y2 = np.max(landmarks, axis=0)\n",
    "        roi = gray[y1:y2, x1:x2]\n",
    "\n",
    "        # Redimensiona a região de interesse para o tamanho esperado pelo modelo\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "\n",
    "        # Normaliza a região de interesse\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "\n",
    "        # Adiciona uma dimensão extra ao tensor de entrada do modelo\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        roi = np.expand_dims(roi, axis=-1)\n",
    "\n",
    "        # Classifica a emoção da região de interesse\n",
    "        predictions = model.predict(roi)\n",
    "        label = emotions[np.argmax(predictions)]\n",
    "\n",
    "        # Desenha um retângulo em torno do rosto\n",
    "        cv2.rectangle(frame, (x1*4, y1*4), (x2*4, y2*4), (0, 255, 0), 2)\n",
    "\n",
    "        # Escreve o rótulo da emoção sobre o retângulo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
